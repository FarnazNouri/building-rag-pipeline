{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b805c3cd",
   "metadata": {},
   "source": [
    "# LangChain Document Structure\n",
    "\n",
    "## from langchain.schema import Document\n",
    "\n",
    "### Core Components:\n",
    "    - page_content(str)\n",
    "    - metadata(dict)\n",
    "\n",
    "### LangChain Loader\n",
    "    - give you the content of a data (csv, pdf,...) to a document structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca5f1fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document Structure\n",
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86f7defe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'example.txt', 'pages': 1, 'author': 'Farnaz Nouri', 'data_created': '2025-10-01'}, page_content='this is the main text content I am using to create RAG')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = Document(\n",
    "    page_content = \"this is the main text content I am using to create RAG\",\n",
    "    metadata = {\n",
    "        'source': 'example.txt',\n",
    "        'pages': 1,\n",
    "        'author': \"Farnaz Nouri\",\n",
    "        'data_created': '2025-10-01'\n",
    "    }\n",
    ")\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e2acc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple txt file\n",
    "import os\n",
    "os.makedirs('../data/text_files', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8e0d822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample text file created!\n"
     ]
    }
   ],
   "source": [
    "sample_texts = {\n",
    "    \"../data/text_files/python_intro.txt\":'''Python is a high-level, interpreted programming language known for its readability and versatility. Created by Guido van Rossum and released in 1991, it has become one of the most popular languages for various applications.\n",
    "Key Characteristics:\n",
    "Readability: Python's syntax emphasizes clarity and conciseness, often allowing developers to express concepts in fewer lines of code compared to other languages. This is partly due to its use of indentation to define code blocks.\n",
    "Interpreted: Python code is executed line by line by an interpreter, which facilitates rapid prototyping and interactive testing.\n",
    "Dynamically Typed: Variable types are automatically determined at runtime, simplifying code writing as explicit type declarations are not always required.\n",
    "Multi-paradigm: Python supports various programming paradigms, including object-oriented, procedural, and functional programming.\n",
    "Extensive Standard Library: Python comes with a large standard library that provides modules and functions for a wide range of tasks, reducing the need to write code from scratch.\n",
    "Cross-platform: Python applications can be developed and run on different operating systems like Windows, macOS, and Linux.\n",
    "Common Applications:\n",
    "Web Development: Used for server-side web applications with frameworks like Django and Flask.\n",
    "Data Science and Machine Learning: A popular choice due to its powerful libraries such as NumPy, Pandas, and scikit-learn.\n",
    "Automation and Scripting: Ideal for automating repetitive tasks and system administration.\n",
    "Software Development: Used for creating desktop applications, games, and internal tools.\n",
    "Scientific Computing and Research: Employed in various scientific fields for data analysis and modeling.\n",
    "    ''',\n",
    "    \"../data/text_files/machine_learning.txt\": ''' \n",
    "Machine learning allows computers to learn from data and improve performance on tasks without explicit programming. The core process involves collecting and preparing data, selecting an algorithm, training a model, and evaluating its accuracy to make predictions. The three primary types of machine learning are supervised learning (using labeled data for tasks like classification and regression), unsupervised learning (finding patterns in unlabeled data, like clustering), and reinforcement learning (learning from rewards and penalties in an environment).\n",
    "Key Concepts\n",
    "Data is Crucial: High-quality, diverse data is the foundation of machine learning, providing the examples for models to learn from. \n",
    "Algorithms & Models: An algorithm is a set of instructions that enables the computer to learn from data, while a model is the trained output of the algorithm. \n",
    "Features: These are the attributes or characteristics extracted from data that are used by the model to learn and make decisions. \n",
    "Types of Machine Learning\n",
    "Supervised Learning:\n",
    "How it works: Uses labeled datasets, where the correct input-output relationships are known, to train the model. \n",
    "Examples: Image recognition (labeling photos as \"cat\" or \"dog\") and spam email filtering. \n",
    "Unsupervised Learning:\n",
    "How it works: Works with unlabeled data to identify hidden patterns, similarities, and groupings on its own. \n",
    "Examples: Clustering data points to find common characteristics or detecting anomalies in datasets. \n",
    "Reinforcement Learning:\n",
    "How it works: An agent learns by interacting with an environment, receiving feedback in the form of rewards or penalties for its actions. \n",
    "Examples: Training a robot to navigate or a program to play a game by playing against itself.\n",
    "'''\n",
    "}\n",
    "\n",
    "for filepath, content in sample_texts.items():\n",
    "    with open(filepath, 'w', encoding=\"utf-8\") as f:\n",
    "        f.write(content)\n",
    "\n",
    "print(\"sample text file created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef930a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': '../data/text_files/python_intro.txt'}, page_content=\"Python is a high-level, interpreted programming language known for its readability and versatility. Created by Guido van Rossum and released in 1991, it has become one of the most popular languages for various applications.\\nKey Characteristics:\\nReadability: Python's syntax emphasizes clarity and conciseness, often allowing developers to express concepts in fewer lines of code compared to other languages. This is partly due to its use of indentation to define code blocks.\\nInterpreted: Python code is executed line by line by an interpreter, which facilitates rapid prototyping and interactive testing.\\nDynamically Typed: Variable types are automatically determined at runtime, simplifying code writing as explicit type declarations are not always required.\\nMulti-paradigm: Python supports various programming paradigms, including object-oriented, procedural, and functional programming.\\nExtensive Standard Library: Python comes with a large standard library that provides modules and functions for a wide range of tasks, reducing the need to write code from scratch.\\nCross-platform: Python applications can be developed and run on different operating systems like Windows, macOS, and Linux.\\nCommon Applications:\\nWeb Development: Used for server-side web applications with frameworks like Django and Flask.\\nData Science and Machine Learning: A popular choice due to its powerful libraries such as NumPy, Pandas, and scikit-learn.\\nAutomation and Scripting: Ideal for automating repetitive tasks and system administration.\\nSoftware Development: Used for creating desktop applications, games, and internal tools.\\nScientific Computing and Research: Employed in various scientific fields for data analysis and modeling.\\n    \")]\n"
     ]
    }
   ],
   "source": [
    "# TextLoader\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "# from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"../data/text_files/python_intro.txt\", encoding='utf-8')\n",
    "document = loader.load()\n",
    "print(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c5d32e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '../data/text_files/python_intro.txt'}, page_content=\"Python is a high-level, interpreted programming language known for its readability and versatility. Created by Guido van Rossum and released in 1991, it has become one of the most popular languages for various applications.\\nKey Characteristics:\\nReadability: Python's syntax emphasizes clarity and conciseness, often allowing developers to express concepts in fewer lines of code compared to other languages. This is partly due to its use of indentation to define code blocks.\\nInterpreted: Python code is executed line by line by an interpreter, which facilitates rapid prototyping and interactive testing.\\nDynamically Typed: Variable types are automatically determined at runtime, simplifying code writing as explicit type declarations are not always required.\\nMulti-paradigm: Python supports various programming paradigms, including object-oriented, procedural, and functional programming.\\nExtensive Standard Library: Python comes with a large standard library that provides modules and functions for a wide range of tasks, reducing the need to write code from scratch.\\nCross-platform: Python applications can be developed and run on different operating systems like Windows, macOS, and Linux.\\nCommon Applications:\\nWeb Development: Used for server-side web applications with frameworks like Django and Flask.\\nData Science and Machine Learning: A popular choice due to its powerful libraries such as NumPy, Pandas, and scikit-learn.\\nAutomation and Scripting: Ideal for automating repetitive tasks and system administration.\\nSoftware Development: Used for creating desktop applications, games, and internal tools.\\nScientific Computing and Research: Employed in various scientific fields for data analysis and modeling.\\n    \"),\n",
       " Document(metadata={'source': '../data/text_files/machine_learning.txt'}, page_content=' \\nMachine learning allows computers to learn from data and improve performance on tasks without explicit programming. The core process involves collecting and preparing data, selecting an algorithm, training a model, and evaluating its accuracy to make predictions. The three primary types of machine learning are supervised learning (using labeled data for tasks like classification and regression), unsupervised learning (finding patterns in unlabeled data, like clustering), and reinforcement learning (learning from rewards and penalties in an environment).\\nKey Concepts\\nData is Crucial: High-quality, diverse data is the foundation of machine learning, providing the examples for models to learn from. \\nAlgorithms & Models: An algorithm is a set of instructions that enables the computer to learn from data, while a model is the trained output of the algorithm. \\nFeatures: These are the attributes or characteristics extracted from data that are used by the model to learn and make decisions. \\nTypes of Machine Learning\\nSupervised Learning:\\nHow it works: Uses labeled datasets, where the correct input-output relationships are known, to train the model. \\nExamples: Image recognition (labeling photos as \"cat\" or \"dog\") and spam email filtering. \\nUnsupervised Learning:\\nHow it works: Works with unlabeled data to identify hidden patterns, similarities, and groupings on its own. \\nExamples: Clustering data points to find common characteristics or detecting anomalies in datasets. \\nReinforcement Learning:\\nHow it works: An agent learns by interacting with an environment, receiving feedback in the form of rewards or penalties for its actions. \\nExamples: Training a robot to navigate or a program to play a game by playing against itself.\\n')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Directory Loader -> if you have all the documents in your directory \n",
    "# and want to load all of them\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "# Load all the text files from the directory\n",
    "dir_loader = DirectoryLoader(\n",
    "    '../data/text_files',\n",
    "    glob= \"**/*.txt\", # pattern to match files - corrected pattern\n",
    "    loader_cls= TextLoader,\n",
    "    loader_kwargs={'encoding':'utf-8'},\n",
    "    show_progress=False\n",
    ")\n",
    "documents = dir_loader.load()\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "403a88be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'Skia/PDF m142 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'attention', 'source': '../data/pdf_files/attention.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}, page_content='NLP,  attention  mechanisms  enable  a  model  to  dynamically  weigh  the  importance  of  different  \\nwords\\n \\nin\\n \\nan\\n \\ninput\\n \\nsequence,\\n \\nallowing\\n \\nit\\n \\nto\\n \\nfocus\\n \\non\\n \\nthe\\n \\nmost\\n \\nrelevant\\n \\nparts\\n \\nof\\n \\nthe\\n \\ncontext\\n \\nwhen\\n \\nprocessing\\n \\ninformation\\n \\nor\\n \\ngenerating\\n \\noutput.\\n \\nThis\\n \\nimproves\\n \\nunderstanding\\n \\nof\\n \\nlong-range\\n \\ndependencies,\\n \\nlike\\n \\n\"dog\"\\n \\nand\\n \\n\"field\"\\n \\nin\\n \\n\"The\\n \\ndog\\n \\nran\\n \\nacross\\n \\nthe\\n \\nfield,\"\\n \\nand\\n \\nis\\n \\na\\n \\nfoundational\\n component  of  modern  Transformer  models,  powering  tasks  from  text  generation to  translation.    How  Attention  Works  At  its  core,  attention  works  by  using  the  concepts  of  queries,  keys,  and  values  to  determine  how  \\nrelevant\\n \\ndifferent\\n \\nparts\\n \\nof\\n \\nthe\\n \\ninput\\n \\nsequence\\n \\nare\\n \\nto\\n \\na\\n \\ngiven\\n \\nword\\n \\nor\\n \\noutput.\\n \\n ●  Query  (Q):  Represents  the  current  input  (e.g.,  the  word  being  processed)  that  is  looking  \\nfor\\n \\nrelevant\\n \\ninformation.\\n \\n ●   ●  Keys  (K):  Act  as  \"labels\"  or  identifiers  for  each  part  of  the  input  data.   ●   ●  Values  (V):  Contain  the  actual  information  that  will  be  retrieved  or  weighted.   ●   The  model  calculates  an  \"attention  score\"  by  comparing  the  query  with  each  key.These  scores  are  then  normalized  using  a  softmax  function to  produce  attention  weights.  Finally,  these  weights  are  used  to  compute  a  weighted  sum  of  the  corresponding  values,  producing  a  refined  \\nrepresentation\\n \\nthat\\n \\nemphasizes\\n \\nthe\\n \\nmost\\n \\nimportant\\n \\ncontext.\\n \\n Key  Types  of  Attention  ●  Self-Attention:  A  crucial  innovation  in  the  Transformer  architecture,  where  queries,  keys,  and  values  are  all  derived  from  the  same  input  sequence.  This  allows  tokens  within  the  \\nsequence\\n \\nto\\n \\nattend\\n \\nto\\n \\neach\\n \\nother,\\n \\ncapturing\\n \\ninternal\\n \\nrelationships\\n \\nand\\n \\ncontext.\\n \\n ●  Multi-Head  Attention:  In  this  technique,  multiple  attention  mechanisms  are  run  in  parallel.  Each  \"head\"  can  learn  different  types  of  relationships,  allowing  the  model  to  grasp  \\nvarious\\n \\npatterns\\n \\nand\\n \\nnuances\\n \\nwithin\\n \\nthe\\n \\ntext.\\n \\n Why  Attention  is  Important  ●  Improved  Contextual  Understanding:  Attention  allows  models  to  capture  dependencies  \\nbetween\\n \\nwords\\n \\nthat\\n \\nare\\n \\nfar\\n \\napart\\n \\nin\\n \\na\\n \\nsentence,\\n \\nleading\\n \\nto\\n \\na\\n \\nricher\\n \\nunderstanding\\n \\nof\\n \\nmeaning.\\n \\n ●  Enhanced  Performance:  It  has  significantly  improved  performance  in  many  NLP  tasks,  \\nincluding\\n \\ntext\\n \\ngeneration,\\n \\ntranslation,\\n \\nand\\n \\ntext\\n \\nsummarization.\\n \\n ●  Computational  Efficiency:  By  enabling  parallel  processing  of  sequences,  attention  mechanisms  are  more  computationally  efficient  than  older,  recurrent  neural  network  (RNN) based  models,  which  process  information  sequentially.'),\n",
       " Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2025-08-07T19:40:52+00:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2025-08-07T19:40:52+00:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': '../data/pdf_files/Technical_Topics_Cheat_Sheet.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}, page_content=\"End-to-End ML Pipeline\\nImagine you’re baking a cake. You gather ingredients (data ingestion), mix and prepare them (data\\ncleaning, feature engineering), bake the cake (train your model), taste-test it (evaluate), then serve it to\\nothers (deploy and monitor). That’s an ML pipeline — taking data from raw to useful predictions.\\nSupervised, Unsupervised & Reinforcement Learning\\nSupervised: You give the computer the question and the answer, and it learns to match them (like\\nteaching with flashcards). Unsupervised: You just give the computer the data, and it finds patterns on\\nits own (like sorting LEGO pieces by shape without labels). Reinforcement: The computer learns by\\ntrying, getting rewards for good actions (like a dog learning tricks with treats).\\nTime Series Forecasting & Monte Carlo Simulation\\nTime series is like trying to guess tomorrow’s weather based on past patterns. Monte Carlo simulation\\nis like rolling dice many times to guess the chances of something happening — helpful when you’re\\nunsure and want to understand all possible outcomes.\\nNLP & LLMs\\nNLP is how computers read, understand, and write human language. LLMs (like ChatGPT) are trained\\non lots of text and can answer questions, write summaries, or even draft emails — like a very smart\\nintern who reads a million books a day.\\nMLOps + Cloud Deployment\\nMLOps is like DevOps for ML — it helps you build, ship, and maintain ML models smoothly. Cloud tools\\nlike AWS let you run projects on someone else’s supercomputer, so you can scale models reliably, like\\nturning a food truck into a restaurant chain.\\nData Visualization & Storytelling\\nData visualization turns numbers into pictures so people can see patterns — think graphs, charts,\\ndashboards. Storytelling is explaining those patterns so someone can make a smart decision — like\\nturning a traffic map into 'Take Route B — it’s faster!'\\nReal-World Data (RWD)\\nRWD is messy, like kids’ drawings on paper — lots of creativity, but not always clean. It comes from\\nreal people: hospital records, prescriptions, sales logs. You have to clean it, match things up, and make\\nsure it’s trustworthy before using it.\\nVersion Control & Collaboration (Git, Agile)\\nGit is like Google Docs for code — it tracks changes, lets you go back, and lets your team work\\ntogether. Agile means breaking big jobs into small pieces, sharing updates often, and adjusting as you\\ngo — like building LEGO castles one section at a time.\"),\n",
       " Document(metadata={'producer': 'Skia/PDF m142 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'embedding', 'source': '../data/pdf_files/embedding.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}, page_content='●   An  embedding  is  a  data  representation  that  uses  low-dimensional  numerical  vectors  to  capture  \\nthe\\n \\nsemantic\\n \\nmeaning\\n \\nand\\n \\nrelationships\\n \\nof\\n \\nnon-numerical\\n \\ndata\\n \\nlike\\n \\nwords,\\n \\nimages,\\n \\nor\\n \\ngraphs,\\n \\nmaking\\n \\nthem\\n \\nunderstandable\\n \\nfor\\n \\nmachine\\n \\nlearning\\n \\nmodels.\\n \\nThese\\n \\ndense\\n \\nvectors\\n \\nare\\n \\ncreated\\n \\nthrough\\n \\na\\n \\nprocess\\n \\nof\\n \\nmapping\\n \\ncomplex,\\n \\nreal-world\\n \\ndata\\n \\ninto\\n \\na\\n \\nvector\\n \\nspace,\\n \\nwhere\\n \\nthe\\n \\ndistance\\n \\nbetween\\n \\nembeddings\\n \\nreflects\\n \\nthe\\n \\nsimilarity\\n \\nof\\n \\nthe\\n \\noriginal\\n \\ndata\\n \\npoints.\\n \\nFor\\n \\ninstance,\\n \\nin\\n \\nnatural\\n \\nlanguage\\n \\nprocessing\\n \\n(NLP),\\n \\nword\\n \\nembeddings\\n \\nallow\\n \\nfor\\n \\nmathematical\\n \\noperations\\n \\nthat\\n \\nrepresent\\n \\nrelationships,\\n \\nlike\\n \\nking\\n \\n-\\n \\nman\\n \\n+\\n \\nwoman\\n \\n≈\\n \\nqueen,\\n \\nto\\n \\nuncover\\n \\ndeeper\\n \\nmeaning\\n \\nand\\n \\nenable\\n \\ntasks\\n \\nsuch\\n \\nas\\n \\nsentiment\\n \\nanalysis\\n \\nand\\n \\nmachine\\n \\ntranslation.\\n  \\n What  is  the  process?  ●  Data  Transformation:  Non-numerical  data  (text,  images,  graphs)  is  converted  into  numerical  vectors,  where  each  dimension  represents  a  specific  feature  of  the  data.   ●  Vector  Space:  These  vectors  are  placed  into  an  n-dimensional  space,  creating  a  dense  numerical  representation.   ●  Semantic  Relationships:  The  embedding  process  captures  the  nuances  and  context  of  the  original  data.  For  example,  words  with  similar  meanings  will  have  embeddings  that  \\nare\\n \\ncloser\\n \\ntogether\\n \\nin\\n \\nthe\\n \\nvector\\n \\nspace.\\n \\n ●  Machine  Learning  Use:  These  vectors  can  then  be  used  by  machine  learning  models  for  tasks  like  classification,  search,  recommendation  systems,  and  more.   Key  Characteristics  and  Benefits  ●  Information  Density:  Embeddings  provide  an  information-dense  representation,  meaning  \\nthey\\n \\npack\\n \\na\\n \\nlot\\n \\nof\\n \\nmeaning\\n \\ninto\\n \\nfewer\\n \\ndimensions\\n \\nthan\\n \\ntraditional\\n \\nmethods.\\n \\n ●  Semantic  Similarity:  The  distance  between  two  embeddings  in  the  vector  space  \\ncorrelates\\n \\nwith\\n \\nthe\\n \\nsemantic\\n \\nsimilarity\\n \\nof\\n \\nthe\\n \\noriginal\\n \\ninputs.\\n \\n ●  Machine-Readable  Format:  Embeddings  make  complex  data  understandable  to  \\ncomputers\\n \\nand\\n \\nalgorithms,\\n \\nwhich\\n \\nonly\\n \\nprocess\\n \\nnumerical\\n \\ninputs.\\n \\n ●  Capture  of  Relationships:  Embeddings  can  capture  intricate  relationships  within  the  data,  \\nsuch\\n \\nas\\n \\nco-occurrence\\n \\npatterns\\n \\nin\\n \\ntext\\n \\nor\\n \\nstructural\\n \\nrelationships\\n \\nin\\n \\ngraphs.\\n \\n Examples  of  Embeddings  ●  Word  Embeddings:  Represent  words  as  vectors,  enabling  tasks  like  sentiment  analysis  and  machine  translation.   ●  Image  Embeddings:  Map  images  into  a  vector  space  to  group  similar  images  and  enable  visual  content  retrieval.   ●  Graph  Embeddings:  Convert  nodes  and  edges  in  graphs  into  numerical  vectors  to  understand  relationships  and  predict  links.')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Directory Loader for PDF files\n",
    "from langchain_community.document_loaders import DirectoryLoader, PyPDFLoader\n",
    "\n",
    "# First, let's create the pdf_files directory and add a sample PDF (if needed)\n",
    "import os\n",
    "os.makedirs('../data/pdf_files', exist_ok=True)\n",
    "\n",
    "# Load all the PDF files from the directory\n",
    "dir_loader = DirectoryLoader(\n",
    "    '../data/pdf_files',\n",
    "    glob= \"**/*.pdf\", # pattern to match files - corrected pattern\n",
    "    loader_cls= PyPDFLoader,\n",
    "    show_progress=False\n",
    ")\n",
    "pdf_documents = dir_loader.load()\n",
    "pdf_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ecd4c7",
   "metadata": {},
   "source": [
    "# Embedding And VectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f9cbd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the imports with Python 3.12\n",
    "import numpy as np\n",
    "import chromadb\n",
    "import uuid\n",
    "from chromadb.config import Settings\n",
    "from typing import List, Dict, Any, Tuple\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950d4805",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "building-rag-pipeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
